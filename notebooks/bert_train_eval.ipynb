{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install \"transformers>=4.42\" \"datasets>=2.20\" \"evaluate>=0.4.2\" \"scikit-learn>=1.5\" \"accelerate>=0.30\" \"tqdm>=4.66\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import sys, numpy, torch, transformers, datasets, sklearn\n",
    "print(sys.version)\n",
    "print(\"numpy\", numpy.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"transformers\", transformers.__version__)\n",
    "print(\"datasets\", datasets.__version__)\n"
   ],
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
      "numpy 2.0.2\n",
      "torch 2.8.0+cu126\n",
      "transformers 4.56.1\n",
      "datasets 4.0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clone the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "REPO_URL = \"https://github.com/Dimasss16/nlp-offensive-language-classifier.git\" # some url...\n",
    "BRANCH   = \"main\"\n",
    "VERIFY_DATA = True\n",
    "\n",
    "import os, subprocess, shutil, csv\n",
    "from pathlib import Path\n",
    "\n",
    "%cd /content\n",
    "repo_dir = REPO_URL.rsplit(\"/\", 1)[-1].replace(\".git\", \"\")\n",
    "if Path(repo_dir).exists():\n",
    "    print(f\"Repo '{repo_dir}' exists — pulling latest…\")\n",
    "    %cd /content/{repo_dir}\n",
    "    if BRANCH:\n",
    "        subprocess.run([\"git\", \"fetch\", \"origin\", BRANCH], check=True)\n",
    "        subprocess.run([\"git\", \"checkout\", BRANCH], check=True)\n",
    "        subprocess.run([\"git\", \"reset\", \"--hard\", f\"origin/{BRANCH}\"], check=True)\n",
    "    else:\n",
    "        subprocess.run([\"git\", \"pull\"], check=True)\n",
    "else:\n",
    "    print(\"Cloning the repo\")\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL], check=True)\n",
    "    %cd /content/{repo_dir}\n",
    "    if BRANCH:\n",
    "        subprocess.run([\"git\", \"checkout\", BRANCH], check=True)\n",
    "\n",
    "print(\"Repo root:\", Path.cwd())\n",
    "\n",
    "def short_tree(root=\".\", max_depth=2):\n",
    "    root = Path(root)\n",
    "    for p in sorted(root.rglob(\"*\")):\n",
    "        depth = len(p.relative_to(root).parts)\n",
    "        if depth <= max_depth:\n",
    "            print(\"  \" * (depth-1) + (\"├─ \" if depth>0 else \"\") + p.name)\n",
    "\n",
    "short_tree(\".\", max_depth=2)\n",
    "\n",
    "\n",
    "if VERIFY_DATA:\n",
    "    expected = [\n",
    "        \"src/data/processed_bert/train.csv\",\n",
    "        \"src/data/processed_bert/train_augmented.csv\",\n",
    "        \"src/data/processed_bert/val.csv\",\n",
    "        \"src/data/processed_bert/test.csv\",\n",
    "    ]\n",
    "    missing = []\n",
    "    for rel in expected:\n",
    "        p = Path(rel)\n",
    "        if p.exists():\n",
    "            print(f\"{rel} ({p.stat().st_size/1e6:.2f} MB) exists\")\n",
    "\n",
    "    def peek_csv(path, n=2):\n",
    "        path = Path(path)\n",
    "        try:\n",
    "            with path.open(newline=\"\", encoding=\"utf-8\") as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                headers = reader.fieldnames or []\n",
    "                print(f\"\\n{path} headers:\", headers)\n",
    "                required = {\"text\", \"clean_text\", \"label\"}\n",
    "                lowered = {h.lower() for h in headers}\n",
    "                print(\"Columns OK.\" if required.issubset(lowered)\n",
    "                      else f\"Missing columns: {sorted(required - lowered)}\")\n",
    "                for _, row in zip(range(n), reader):\n",
    "                    row_show = {k: (v[:80]+\"…\") if isinstance(v, str) and len(v) > 80 else v\n",
    "                                for k, v in row.items()}\n",
    "                    print(row_show)\n",
    "        except Exception as e:\n",
    "            print(f\"Peek failed for {path}: {e}\")\n",
    "\n",
    "    for rel in expected:\n",
    "        if Path(rel).exists():\n",
    "            peek_csv(rel)\n"
   ],
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "Cloning the repo\n",
      "/content/nlp-offensive-language-classifier\n",
      "Repo root: /content/nlp-offensive-language-classifier\n",
      "├─ .DS_Store\n",
      "├─ .git\n",
      "  ├─ HEAD\n",
      "  ├─ branches\n",
      "  ├─ config\n",
      "  ├─ description\n",
      "  ├─ hooks\n",
      "  ├─ index\n",
      "  ├─ info\n",
      "  ├─ logs\n",
      "  ├─ objects\n",
      "  ├─ packed-refs\n",
      "  ├─ refs\n",
      "├─ .gitignore\n",
      "├─ .idea\n",
      "  ├─ inspectionProfiles\n",
      "  ├─ libraries\n",
      "  ├─ misc.xml\n",
      "  ├─ modules.xml\n",
      "  ├─ nlp-offensive-language-classifier.iml\n",
      "  ├─ prettier.xml\n",
      "  ├─ vcs.xml\n",
      "  ├─ workspace.xml\n",
      "├─ .python-version\n",
      "├─ LICENSE\n",
      "├─ README.md\n",
      "├─ models\n",
      "  ├─ .DS_Store\n",
      "  ├─ .gitkeep\n",
      "  ├─ bert_augmented\n",
      "  ├─ bert_original\n",
      "  ├─ logreg\n",
      "  ├─ majority\n",
      "├─ notebooks\n",
      "  ├─ bert_training.ipynb\n",
      "  ├─ bert_training_fixed.ipynb\n",
      "  ├─ perturbation_tests.ipynb\n",
      "  ├─ stage1_evaluation.ipynb\n",
      "  ├─ {01_eda.ipynb}\n",
      "├─ predictions\n",
      "  ├─ .DS_Store\n",
      "  ├─ bert\n",
      "  ├─ logreg\n",
      "  ├─ majority\n",
      "├─ requirements.txt\n",
      "├─ results\n",
      "  ├─ stage1_confusion_matrices.png\n",
      "  ├─ stage1_overall_metrics.csv\n",
      "  ├─ stage1_per_class_comparison.png\n",
      "├─ run_phase1.py\n",
      "├─ src\n",
      "  ├─ .DS_Store\n",
      "  ├─ __init__.py\n",
      "  ├─ config.py\n",
      "  ├─ data\n",
      "  ├─ data_augmentation.py\n",
      "  ├─ data_loader.py\n",
      "  ├─ data_perturbation.py\n",
      "  ├─ majority_baseline.py\n",
      "  ├─ preprocessing.py\n",
      "  ├─ tf_idf_baseline.py\n",
      "src/data/processed_bert/train.csv (2.82 MB) exists\n",
      "src/data/processed_bert/train_augmented.csv (3.66 MB) exists\n",
      "src/data/processed_bert/val.csv (0.61 MB) exists\n",
      "src/data/processed_bert/test.csv (0.60 MB) exists\n",
      "\n",
      "src/data/processed_bert/train.csv headers: ['text', 'label', 'clean_text']\n",
      "Columns OK.\n",
      "{'text': 'LMFAOOOOOO GAY AS FUCK RT @PubesOnFleeK: &#128557;&#128557;&#128557;&#128557;&#1…', 'label': '1', 'clean_text': 'LMFAOOOOOO GAY AS FUCK RT @user get these two faggots off my TL [URL]'}\n",
      "{'text': 'RT @OGTREEZ: Steve found out you can\\'t call Taiquaniesha a \"stupid fuckin cunt\" …', 'label': '1', 'clean_text': 'RT @user Steve found out you can\\'t call Taiquaniesha a \"stupid fuckin cunt\" like…'}\n",
      "\n",
      "src/data/processed_bert/train_augmented.csv headers: ['text', 'label', 'clean_text']\n",
      "Columns OK.\n",
      "{'text': 'LMFAOOOOOO GAY AS FUCK RT @PubesOnFleeK: &#128557;&#128557;&#128557;&#128557;&#1…', 'label': '1', 'clean_text': 'LMFAOOOOOO GAY AS FUCK RT @user get these two faggots off my TL [URL]'}\n",
      "{'text': 'RT @OGTREEZ: Steve found out you can\\'t call Taiquaniesha a \"stupid fuckin cunt\" …', 'label': '1', 'clean_text': 'RT @user Steve found out you can\\'t call Taiquaniesha a \"stupid fuckin cunt\" like…'}\n",
      "\n",
      "src/data/processed_bert/val.csv headers: ['text', 'label', 'clean_text']\n",
      "Columns OK.\n",
      "{'text': 'You fucking fag &#8220;@baethingape: this is exactly what i am talking about \\n\\nw…', 'label': '0', 'clean_text': 'You fucking fag @user this is exactly what i am talking about women are pigs [UR…'}\n",
      "{'text': \"RT @CoCoMilan18: &#8220;@Me1st_u_last: This bitch @GOTDAMNCHAT ain't got a bit o…\", 'label': '1', 'clean_text': \"RT @user @user This bitch @user ain't got a bit of sense lmaoo!! [URL]#8221;\"}\n",
      "\n",
      "src/data/processed_bert/test.csv headers: ['text', 'label', 'clean_text']\n",
      "Columns OK.\n",
      "{'text': 'RT @funkQdelic_ACE: Waka Flaka a lucky retard lol', 'label': '1', 'clean_text': 'RT @user Waka Flaka a lucky retard lol'}\n",
      "{'text': 'Yea I see ya hoe', 'label': '1', 'clean_text': 'Yea I see ya hoe'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"[setup] Device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"[setup] here is the GPU: {torch.cuda.get_device_name(0)}\")"
   ],
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[setup] Device: cuda\n",
      "[setup] here is the GPU: Tesla T4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "BASE_DIR = Path('src/data')\n",
    "MODELS_DIR = Path('models')\n",
    "RESULTS_DIR = Path('results')\n",
    "\n",
    "VAL_PATH = BASE_DIR / 'processed_bert/val.csv'\n",
    "TEST_PATH = BASE_DIR / 'processed_bert/test.csv'\n",
    "\n",
    "CONFIG = {\n",
    "    'model_name': 'bert-base-uncased',\n",
    "    'max_length': 128,\n",
    "    'num_labels': 3,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "CLASS_NAMES = {0: 'hate_speech', 1: 'offensive', 2: 'neither'}\n",
    "\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])"
   ],
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd9192b04d0>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def load_train_data(use_augmented=False):\n",
    "    if use_augmented:\n",
    "        path = BASE_DIR / 'processed_bert/train_augmented.csv'\n",
    "        print(f\"Loading AUGMENTED training data\")\n",
    "    else:\n",
    "        path = BASE_DIR / 'processed_bert/train.csv'\n",
    "        print(f\"Loading ORIGINAL training data\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Loaded {len(df):,} samples from {path.name}\")\n",
    "    return df"
   ],
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_orig = load_train_data(use_augmented=False)\n",
    "train_aug = load_train_data(use_augmented=True)\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ],
   "metadata": {},
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading ORIGINAL training data\n",
      "Loaded 17,347 samples from train.csv\n",
      "Loading AUGMENTED training data\n",
      "Loaded 22,263 samples from train_augmented.csv\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Val: {len(val_df):,} samples\")"
   ],
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val: 3,718 samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Test: {len(test_df):,} samples\")"
   ],
   "metadata": {},
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test: 3,718 samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def peek_data(df, name=\"Dataset\"):\n",
    "    print(f\"\\n[peek] {name}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "\n",
    "    dist = df['label'].value_counts().sort_index()\n",
    "    print(f\"  Classes:\")\n",
    "    for label, count in dist.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"    {CLASS_NAMES[label]:12s}: {count:5d} ({pct:5.1f}%)\")\n",
    "\n",
    "\n",
    "peek_data(train_orig, \"Original Training\")\n",
    "peek_data(train_aug, \"Augmented Training\")\n",
    "peek_data(val_df, \"Validation\")"
   ],
   "metadata": {},
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[peek] Original Training\n",
      "  Shape: (17347, 3)\n",
      "  Columns: ['text', 'label', 'clean_text']\n",
      "  Classes:\n",
      "    hate_speech :  1001 (  5.8%)\n",
      "    offensive   : 13432 ( 77.4%)\n",
      "    neither     :  2914 ( 16.8%)\n",
      "\n",
      "[peek] Augmented Training\n",
      "  Shape: (22263, 3)\n",
      "  Columns: ['text', 'label', 'clean_text']\n",
      "  Classes:\n",
      "    hate_speech :  3003 ( 13.5%)\n",
      "    offensive   : 13432 ( 60.3%)\n",
      "    neither     :  5828 ( 26.2%)\n",
      "\n",
      "[peek] Validation\n",
      "  Shape: (3718, 3)\n",
      "  Columns: ['text', 'label', 'clean_text']\n",
      "  Classes:\n",
      "    hate_speech :   215 (  5.8%)\n",
      "    offensive   :  2879 ( 77.4%)\n",
      "    neither     :   624 ( 16.8%)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class Weights Calculation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_class_weights(df):\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "    labels = df['label'].values\n",
    "    unique_labels = np.array([0, 1, 2])\n",
    "\n",
    "    weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=unique_labels,\n",
    "        y=labels\n",
    "    )\n",
    "\n",
    "    print(f\"[weights] Computed for {len(df):,} samples:\")\n",
    "    for label, weight in zip(unique_labels, weights):\n",
    "        print(f\"  {CLASS_NAMES[label]:12s}: {weight:.4f}\")\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float32)"
   ],
   "metadata": {},
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "weights_orig = calculate_class_weights(train_orig)\n",
    "weights_aug = calculate_class_weights(train_aug)"
   ],
   "metadata": {},
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[weights] Computed for 17,347 samples:\n",
      "  hate_speech : 5.7766\n",
      "  offensive   : 0.4305\n",
      "  neither     : 1.9843\n",
      "[weights] Computed for 22,263 samples:\n",
      "  hate_speech : 2.4712\n",
      "  offensive   : 0.5525\n",
      "  neither     : 1.2733\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_orig_dataset = Dataset.from_pandas(train_orig[['clean_text', 'label']])\n",
    "print(f\"Original train: {len(train_orig_dataset):,} samples\")\n",
    "\n",
    "train_aug_dataset = Dataset.from_pandas(train_aug[['clean_text', 'label']])\n",
    "print(f\"Augmented train: {len(train_aug_dataset):,} samples\")\n",
    "\n",
    "val_dataset = Dataset.from_pandas(val_df[['clean_text', 'label']])\n",
    "print(f\"Validation: {len(val_dataset):,} samples\")"
   ],
   "metadata": {},
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original train: 17,347 samples\n",
      "Augmented train: 22,263 samples\n",
      "Validation: 3,718 samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_texts(examples):\n",
    "    return tokenizer(\n",
    "        examples['clean_text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )"
   ],
   "metadata": {},
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_orig_tok = train_orig_dataset.map(\n",
    "    tokenize_texts,\n",
    "    batched=True,\n",
    "    desc=\"Tokenizing original\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_aug_tok = train_aug_dataset.map(\n",
    "    tokenize_texts,\n",
    "    batched=True,\n",
    "    desc=\"Tokenizing augmented\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "val_tok = val_dataset.map(\n",
    "    tokenize_texts,\n",
    "    batched=True,\n",
    "    desc=\"Tokenizing validation\"\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_orig_tok = train_orig_tok.rename_column('label', 'labels')\n",
    "train_aug_tok = train_aug_tok.rename_column('label', 'labels')\n",
    "val_tok = val_tok.rename_column('label', 'labels')\n",
    "\n",
    "train_orig_tok.set_format('torch')\n",
    "train_aug_tok.set_format('torch')\n",
    "val_tok.set_format('torch')"
   ],
   "metadata": {},
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample = train_orig_tok[0]\n",
    "\n",
    "print(f\"Label: {sample['labels']} ({CLASS_NAMES[int(sample['labels'])]})\")\n",
    "print(f\"Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"Attention mask shape: {sample['attention_mask'].shape}\")\n",
    "\n",
    "decoded = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "print(f\"Decoded text (first 100 chars): '{decoded[:100]}...'\")\n",
    "\n",
    "num_real_tokens = sample['attention_mask'].sum().item()\n",
    "print(f\"Real tokens: {num_real_tokens} / 128\")"
   ],
   "metadata": {},
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label: 1 (offensive)\n",
      "Input IDs shape: torch.Size([128])\n",
      "Attention mask shape: torch.Size([128])\n",
      "Decoded text (first 100 chars): 'lmfaoooooo gay as fuck rt @ user get these two faggots off my tl [ url ]...'\n",
      "Real tokens: 28 / 128\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting up the training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def get_training_config(use_augmented=False):\n",
    "    train_config = {\n",
    "        'num_train_epochs': 4,\n",
    "        'learning_rate': 3e-5,\n",
    "        'per_device_train_batch_size': 16,\n",
    "        'per_device_eval_batch_size': 32,\n",
    "        'gradient_accumulation_steps': 2,\n",
    "        'weight_decay': 0.01,\n",
    "        'warmup_ratio': 0.1,\n",
    "        'fp16': True,\n",
    "        'seed': CONFIG['seed'],\n",
    "        'eval_strategy': 'epoch',\n",
    "        'save_strategy': 'epoch',\n",
    "        'save_total_limit': 2,\n",
    "        'load_best_model_at_end': True,\n",
    "        'metric_for_best_model': 'f1_macro',\n",
    "        'greater_is_better': True,\n",
    "        'logging_steps': 100,\n",
    "    }\n",
    "\n",
    "    if use_augmented:\n",
    "        train_config['output_dir'] = str(MODELS_DIR / 'bert_augmented')\n",
    "        train_config['run_name'] = 'bert_augmented'\n",
    "    else:\n",
    "        train_config['output_dir'] = str(MODELS_DIR / 'bert_original')\n",
    "        train_config['run_name'] = 'bert_original'\n",
    "\n",
    "    print(f\"[config] Training config for {train_config['run_name']}\")\n",
    "    print(f\"  Output: {train_config['output_dir']}\")\n",
    "    print(f\"  Epochs: {train_config['num_train_epochs']}\")\n",
    "    print(f\"  Effective batch: {train_config['per_device_train_batch_size'] * train_config['gradient_accumulation_steps']}\")\n",
    "\n",
    "    return train_config\n"
   ],
   "metadata": {},
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config_orig = get_training_config(use_augmented=False)\n",
    "config_aug = get_training_config(use_augmented=True)"
   ],
   "metadata": {},
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[config] Training config for bert_original\n",
      "  Output: models/bert_original\n",
      "  Epochs: 4\n",
      "  Effective batch: 32\n",
      "[config] Training config for bert_augmented\n",
      "  Output: models/bert_augmented\n",
      "  Epochs: 4\n",
      "  Effective batch: 32\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config_orig"
   ],
   "metadata": {},
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'num_train_epochs': 4,\n",
       " 'learning_rate': 3e-05,\n",
       " 'per_device_train_batch_size': 16,\n",
       " 'per_device_eval_batch_size': 32,\n",
       " 'gradient_accumulation_steps': 2,\n",
       " 'weight_decay': 0.01,\n",
       " 'warmup_ratio': 0.1,\n",
       " 'fp16': True,\n",
       " 'seed': 42,\n",
       " 'eval_strategy': 'epoch',\n",
       " 'save_strategy': 'epoch',\n",
       " 'save_total_limit': 2,\n",
       " 'load_best_model_at_end': True,\n",
       " 'metric_for_best_model': 'f1_macro',\n",
       " 'greater_is_better': True,\n",
       " 'logging_steps': 100,\n",
       " 'output_dir': 'models/bert_original',\n",
       " 'run_name': 'bert_original'}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config_aug"
   ],
   "metadata": {},
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'num_train_epochs': 4,\n",
       " 'learning_rate': 3e-05,\n",
       " 'per_device_train_batch_size': 16,\n",
       " 'per_device_eval_batch_size': 32,\n",
       " 'gradient_accumulation_steps': 2,\n",
       " 'weight_decay': 0.01,\n",
       " 'warmup_ratio': 0.1,\n",
       " 'fp16': True,\n",
       " 'seed': 42,\n",
       " 'eval_strategy': 'epoch',\n",
       " 'save_strategy': 'epoch',\n",
       " 'save_total_limit': 2,\n",
       " 'load_best_model_at_end': True,\n",
       " 'metric_for_best_model': 'f1_macro',\n",
       " 'greater_is_better': True,\n",
       " 'logging_steps': 100,\n",
       " 'output_dir': 'models/bert_augmented',\n",
       " 'run_name': 'bert_augmented'}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Metrics Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
    "    weighted_f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions,\n",
    "        average=None,\n",
    "        labels=[0, 1, 2]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': macro_f1,\n",
    "        'f1_weighted': weighted_f1,\n",
    "        'hate_speech_precision': precision[0],\n",
    "        'hate_speech_recall': recall[0],\n",
    "        'hate_speech_f1': f1[0],\n",
    "        'offensive_precision': precision[1],\n",
    "        'offensive_recall': recall[1],\n",
    "        'offensive_f1': f1[1],\n",
    "        'neither_precision': precision[2],\n",
    "        'neither_recall': recall[2],\n",
    "        'neither_f1': f1[2],\n",
    "    }"
   ],
   "metadata": {},
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Trainer with Weighted Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "from torch import nn\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights, **kwargs):\n",
    "        if 'tokenizer' in kwargs:\n",
    "            kwargs['processing_class'] = kwargs.pop('tokenizer')\n",
    "        super().__init__(**kwargs)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(self.args.device))\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        loss = self.loss_fn(outputs.logits.view(-1, 3), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "metadata": {},
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training original model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"{train_orig_tok.column_names}\")"
   ],
   "metadata": {},
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['clean_text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The tokenized datasets still contain the original clean_text column, which is a string and can't be converted to tensors for training. That's why we are going to go ahead and remove them and then double check that our columns are in proper format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_orig_tok = train_orig_tok.remove_columns(['clean_text'])\n",
    "train_aug_tok = train_aug_tok.remove_columns(['clean_text'])\n",
    "val_tok = val_tok.remove_columns(['clean_text'])"
   ],
   "metadata": {},
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_orig_tok.set_format('torch')\n",
    "train_aug_tok.set_format('torch')\n",
    "val_tok.set_format('torch')"
   ],
   "metadata": {},
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertForSequenceClassification, TrainingArguments, EarlyStoppingCallback\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# We know that this is gonna happen so we'll just suppress it\n",
    "warnings.filterwarnings('ignore', message='Some weights of BertForSequenceClassification were not initialized')\n",
    "\n",
    "def train_bert(use_augmented=False):\n",
    "    if use_augmented:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TRAINING ON AUGMENTED DATA\")\n",
    "        print(\"=\"*60)\n",
    "        train_dataset = train_aug_tok\n",
    "        class_weights = weights_aug\n",
    "        config = config_aug\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TRAINING ON ORIGINAL DATA\")\n",
    "        print(\"=\"*60)\n",
    "        train_dataset = train_orig_tok\n",
    "        class_weights = weights_orig\n",
    "        config = config_orig\n",
    "\n",
    "    print(f\"[setup] Training samples: {len(train_dataset):,}\")\n",
    "    print(f\"[setup] Validation samples: {len(val_tok):,}\")\n",
    "    print(f\"[setup] Output directory: {config['output_dir']}\")\n",
    "\n",
    "    output_dir = Path(config['output_dir'])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"\\n[model] Loading BERT-base-uncased...\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=3,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    print(f\"[model] Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"[model] Classifier layer initialized randomly (expected)\")\n",
    "\n",
    "    training_config = {k: v for k, v in config.items() if k != 'run_name'}\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        **training_config,\n",
    "        report_to='none',\n",
    "        push_to_hub=False,\n",
    "        remove_unused_columns=True,\n",
    "        dataloader_drop_last=False,\n",
    "        dataloader_num_workers=2,\n",
    "    )\n",
    "\n",
    "    steps_per_epoch = len(train_dataset) // (config['per_device_train_batch_size'] * config['gradient_accumulation_steps'])\n",
    "    total_steps = steps_per_epoch * config['num_train_epochs']\n",
    "\n",
    "    print(f\"\\n[train] Training configuration:\")\n",
    "    print(f\"  Epochs: {config['num_train_epochs']}\")\n",
    "    print(f\"  Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"  Total steps: {total_steps}\")\n",
    "    print(f\"  Effective batch size: {config['per_device_train_batch_size'] * config['gradient_accumulation_steps']}\")\n",
    "    print(f\"  Learning rate: {config['learning_rate']}\")\n",
    "\n",
    "    print(f\"\\n[train] Using class weights: {class_weights.numpy()}\")\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        class_weights=class_weights,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_tok,\n",
    "        processing_class=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    print(\"\\n[train] Starting training\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Training failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"\\n[train] Training complete!\")\n",
    "    print(f\"[train] Final loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "    # Saving everything\n",
    "    best_model_dir = output_dir / 'best_model'\n",
    "    print(f\"\\n[save] Saving model to {best_model_dir}\")\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    trainer.save_model(best_model_dir)\n",
    "    tokenizer.save_pretrained(best_model_dir)\n",
    "\n",
    "    # Save training history\n",
    "    history_file = output_dir / 'training_history.json'\n",
    "\n",
    "    log_history = []\n",
    "    for entry in trainer.state.log_history:\n",
    "        clean_entry = {}\n",
    "        for k, v in entry.items():\n",
    "            if hasattr(v, 'item'):  # numpy scalar\n",
    "                clean_entry[k] = v.item()\n",
    "            elif isinstance(v, (list, dict, str, int, float, bool, type(None))):\n",
    "                clean_entry[k] = v\n",
    "            else:\n",
    "                clean_entry[k] = str(v)\n",
    "        log_history.append(clean_entry)\n",
    "\n",
    "    history = {\n",
    "        'loss_history': log_history,\n",
    "        'best_metric': float(trainer.state.best_metric) if trainer.state.best_metric else None,\n",
    "        'best_model_checkpoint': trainer.state.best_model_checkpoint,\n",
    "        'total_steps': int(trainer.state.global_step),\n",
    "        'epochs_trained': float(trainer.state.epoch),\n",
    "    }\n",
    "\n",
    "    with open(history_file, 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "    print(f\"[save] Training history saved\")\n",
    "\n",
    "    # Save class weights\n",
    "    weights_file = output_dir / 'class_weights.json'\n",
    "    weights_dict = {str(i): float(w) for i, w in enumerate(class_weights.numpy())}\n",
    "    with open(weights_file, 'w') as f:\n",
    "        json.dump(weights_dict, f, indent=2)\n",
    "    print(f\"[save] Class weights saved\")\n",
    "\n",
    "    # Save config\n",
    "    config_file = output_dir / 'training_config.json'\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(f\"[save] Training config saved\")\n",
    "\n",
    "    # Save dataset info\n",
    "    dataset_info = {\n",
    "        'train_samples': len(train_dataset),\n",
    "        'val_samples': len(val_tok),\n",
    "        'augmented': use_augmented,\n",
    "        'dataset_name': 'augmented' if use_augmented else 'original'\n",
    "    }\n",
    "    info_file = output_dir / 'dataset_info.json'\n",
    "    with open(info_file, 'w') as f:\n",
    "        json.dump(dataset_info, f, indent=2)\n",
    "    print(f\"[save] Dataset info saved\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Model saved to: {output_dir}\")\n",
    "\n",
    "    if trainer.state.best_metric:\n",
    "        print(f\"\\nBest validation F1: {trainer.state.best_metric:.4f}\")\n",
    "        print(f\"Training stopped at epoch: {trainer.state.epoch:.1f}\")\n",
    "\n",
    "    return str(output_dir)"
   ],
   "metadata": {},
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_dir_original = train_bert(use_augmented=False)\n",
    "print(f\"Original model saved to: {model_dir_original}\")"
   ],
   "metadata": {},
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING ON ORIGINAL DATA\n",
      "============================================================\n",
      "[setup] Training samples: 17,347\n",
      "[setup] Validation samples: 3,718\n",
      "[setup] Output directory: models/bert_original\n",
      "\n",
      "[model] Loading BERT-base-uncased...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[model] Parameters: 109,484,547\n",
      "[model] Classifier layer initialized randomly (expected)\n",
      "\n",
      "[train] Training configuration:\n",
      "  Epochs: 4\n",
      "  Steps per epoch: 542\n",
      "  Total steps: 2168\n",
      "  Effective batch size: 32\n",
      "  Learning rate: 3e-05\n",
      "\n",
      "[train] Using class weights: [5.776557  0.4304894 1.9843285]\n",
      "\n",
      "[train] Starting training\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2172' max='2172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2172/2172 09:53, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Hate Speech Precision</th>\n",
       "      <th>Hate Speech Recall</th>\n",
       "      <th>Hate Speech F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Neither Precision</th>\n",
       "      <th>Neither Recall</th>\n",
       "      <th>Neither F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.516304</td>\n",
       "      <td>0.805810</td>\n",
       "      <td>0.703112</td>\n",
       "      <td>0.845183</td>\n",
       "      <td>0.222510</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.348178</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.787774</td>\n",
       "      <td>0.872979</td>\n",
       "      <td>0.885350</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.888179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.515860</td>\n",
       "      <td>0.890802</td>\n",
       "      <td>0.758863</td>\n",
       "      <td>0.900333</td>\n",
       "      <td>0.358543</td>\n",
       "      <td>0.595349</td>\n",
       "      <td>0.447552</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.906565</td>\n",
       "      <td>0.935652</td>\n",
       "      <td>0.868381</td>\n",
       "      <td>0.919872</td>\n",
       "      <td>0.893385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.566657</td>\n",
       "      <td>0.887036</td>\n",
       "      <td>0.752030</td>\n",
       "      <td>0.896496</td>\n",
       "      <td>0.346591</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.430335</td>\n",
       "      <td>0.962949</td>\n",
       "      <td>0.902744</td>\n",
       "      <td>0.931875</td>\n",
       "      <td>0.865067</td>\n",
       "      <td>0.924679</td>\n",
       "      <td>0.893881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.721985</td>\n",
       "      <td>0.899139</td>\n",
       "      <td>0.763742</td>\n",
       "      <td>0.904591</td>\n",
       "      <td>0.392617</td>\n",
       "      <td>0.544186</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.955524</td>\n",
       "      <td>0.925321</td>\n",
       "      <td>0.940180</td>\n",
       "      <td>0.889241</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.894904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "[train] Training complete!\n",
      "[train] Final loss: 0.3971\n",
      "\n",
      "[save] Saving model to models/bert_original/best_model\n",
      "[save] Training history saved\n",
      "[save] Class weights saved\n",
      "[save] Training config saved\n",
      "[save] Dataset info saved\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model saved to: models/bert_original\n",
      "\n",
      "Best validation F1: 0.7637\n",
      "Training stopped at epoch: 4.0\n",
      "\n",
      "Original model saved to: models/bert_original\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training augmented model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model_dir_augmented = train_bert(use_augmented=True)\n",
    "print(f\"[complete] Augmented model saved to: {model_dir_augmented}\")"
   ],
   "metadata": {},
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING ON AUGMENTED DATA\n",
      "============================================================\n",
      "[setup] Training samples: 22,263\n",
      "[setup] Validation samples: 3,718\n",
      "[setup] Output directory: models/bert_augmented\n",
      "\n",
      "[model] Loading BERT-base-uncased...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[model] Parameters: 109,484,547\n",
      "[model] Classifier layer initialized randomly (expected)\n",
      "\n",
      "[train] Training configuration:\n",
      "  Epochs: 4\n",
      "  Steps per epoch: 695\n",
      "  Total steps: 2780\n",
      "  Effective batch size: 32\n",
      "  Learning rate: 3e-05\n",
      "\n",
      "[train] Using class weights: [2.4711955 0.5524866 1.2733356]\n",
      "\n",
      "[train] Starting training\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2784' max='2784' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2784/2784 12:07, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Hate Speech Precision</th>\n",
       "      <th>Hate Speech Recall</th>\n",
       "      <th>Hate Speech F1</th>\n",
       "      <th>Offensive Precision</th>\n",
       "      <th>Offensive Recall</th>\n",
       "      <th>Offensive F1</th>\n",
       "      <th>Neither Precision</th>\n",
       "      <th>Neither Recall</th>\n",
       "      <th>Neither F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>0.382379</td>\n",
       "      <td>0.893760</td>\n",
       "      <td>0.758213</td>\n",
       "      <td>0.900388</td>\n",
       "      <td>0.387622</td>\n",
       "      <td>0.553488</td>\n",
       "      <td>0.455939</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.908649</td>\n",
       "      <td>0.937802</td>\n",
       "      <td>0.827004</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.880899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.529157</td>\n",
       "      <td>0.901022</td>\n",
       "      <td>0.760615</td>\n",
       "      <td>0.904155</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.502326</td>\n",
       "      <td>0.450939</td>\n",
       "      <td>0.946906</td>\n",
       "      <td>0.935394</td>\n",
       "      <td>0.941115</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.889789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>0.675929</td>\n",
       "      <td>0.906939</td>\n",
       "      <td>0.753195</td>\n",
       "      <td>0.905829</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.409302</td>\n",
       "      <td>0.424096</td>\n",
       "      <td>0.941420</td>\n",
       "      <td>0.948941</td>\n",
       "      <td>0.945165</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.890323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.846072</td>\n",
       "      <td>0.903712</td>\n",
       "      <td>0.750012</td>\n",
       "      <td>0.903380</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.938747</td>\n",
       "      <td>0.947551</td>\n",
       "      <td>0.943129</td>\n",
       "      <td>0.904841</td>\n",
       "      <td>0.868590</td>\n",
       "      <td>0.886345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "[train] Training complete!\n",
      "[train] Final loss: 0.2646\n",
      "\n",
      "[save] Saving model to models/bert_augmented/best_model\n",
      "[save] Training history saved\n",
      "[save] Class weights saved\n",
      "[save] Training config saved\n",
      "[save] Dataset info saved\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Model saved to: models/bert_augmented\n",
      "\n",
      "Best validation F1: 0.7606\n",
      "Training stopped at epoch: 4.0\n",
      "\n",
      "[complete] Augmented model saved to: models/bert_augmented\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "No more retraining so i'll just save the artifacts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive"
   ],
   "metadata": {},
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "drive.mount('/content/drive')"
   ],
   "metadata": {},
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!cp -r models /content/drive/MyDrive/nlp_offensive_backup/"
   ],
   "metadata": {},
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!ls -lh /content/drive/MyDrive/nlp_offensive_backup/bert_*/best_model/*.safetensors"
   ],
   "metadata": {},
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-rw------- 1 root root 418M Sep 13 19:47 /content/drive/MyDrive/nlp_offensive_backup/bert_augmented/best_model/model.safetensors\n",
      "-rw------- 1 root root 418M Sep 13 19:48 /content/drive/MyDrive/nlp_offensive_backup/bert_original/best_model/model.safetensors\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Eval and perturbation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import (\n",
    "BertTokenizer,\n",
    "BertForSequenceClassification,\n",
    "Trainer,\n",
    "TrainingArguments\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ],
   "metadata": {},
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BASE_DIR = Path('src/data')\n",
    "MODELS_DIR = Path('models')\n",
    "RESULTS_DIR = Path('results')\n",
    "\n",
    "TEST_CSV = BASE_DIR / 'processed_bert/test.csv'\n",
    "OUT_ROOT = Path('results')\n",
    "\n",
    "TEST_PATH_CLEAN = BASE_DIR / \"processed_bert/test.csv\"\n",
    "TEST_PATH_PERTURBED = BASE_DIR / \"processed_bert/test_perturbation.csv\"\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEST_PATHS = {\"clean\": TEST_PATH_CLEAN, \"perturbed\": TEST_PATH_PERTURBED}\n",
    "\n",
    "MODELS  = [\"bert_original\", \"bert_augmented\"]\n",
    "SPLITS  = [\"clean\", \"perturbed\"]"
   ],
   "metadata": {},
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
    "    weighted_f1 = f1_score(labels, predictions, average='weighted')\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average=None, labels=[0,1,2]\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_macro': macro_f1,\n",
    "        'f1_weighted': weighted_f1,\n",
    "        'hate_speech_precision': precision[0], 'hate_speech_recall': recall[0], 'hate_speech_f1': f1[0],\n",
    "        'offensive_precision': precision[1],   'offensive_recall': recall[1],   'offensive_f1': f1[1],\n",
    "        'neither_precision': precision[2],     'neither_recall': recall[2],     'neither_f1': f1[2],\n",
    "    }"
   ],
   "metadata": {},
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_dataset(df, tokenizer, desc=\"perturbed test\"):\n",
    "    dataset = Dataset.from_pandas(df[['clean_text','label']])\n",
    "    def tokenize_batch(ex):\n",
    "        return tokenizer(ex['clean_text'], padding='max_length', truncation=True, max_length=128)\n",
    "    tokenized = dataset.map(tokenize_batch, batched=True, desc=f\"Tokenizing {desc}\")\n",
    "    tokenized = tokenized.rename_column('label','labels')\n",
    "    tokenized = tokenized.remove_columns(['clean_text'])\n",
    "    tokenized.set_format('torch')\n",
    "    return tokenized"
   ],
   "metadata": {},
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def eval(model_name: str, split: str = \"clean\"):\n",
    "    test_path = TEST_PATHS[split]\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    model_dir  = MODELS_DIR / f\"{model_name}\" / \"best_model\"\n",
    "\n",
    "    output_dir = RESULTS_DIR / f\"{model_name}\" / f\"{split}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model     = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "    args = TrainingArguments(output_dir=str(output_dir),\n",
    "                             per_device_eval_batch_size=32,\n",
    "                             report_to='none')\n",
    "    trainer = Trainer(model=model, tokenizer=tokenizer,\n",
    "                      args=args, compute_metrics=compute_metrics)\n",
    "\n",
    "    test_tok = tokenize_dataset(test_df, tokenizer, desc=f\"{split} test\")\n",
    "\n",
    "    print(f\"[{model_name}] Predicting on {split} test…\")\n",
    "    test_output = trainer.predict(test_tok)\n",
    "    test_preds  = np.argmax(test_output.predictions, axis=1)\n",
    "    test_probs  = torch.softmax(torch.tensor(test_output.predictions), dim=-1).numpy()\n",
    "\n",
    "    pd.DataFrame({\n",
    "        'true_label':      test_df['label'].values,\n",
    "        'predicted_label': test_preds,\n",
    "        'prob_hate':       test_probs[:, 0],\n",
    "        'prob_offensive':  test_probs[:, 1],\n",
    "        'prob_neither':    test_probs[:, 2],\n",
    "    }).to_csv(f\"{output_dir}/test_predictions.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame([test_output.metrics]).to_csv(f\"{output_dir}/metrics.csv\", index=False)\n",
    "\n",
    "    print(f\"[{model_name}] Saved to {output_dir}/\")\n",
    "    return test_output.metrics"
   ],
   "metadata": {},
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metrics_orig_clean = eval(\"bert_original\",  split=\"clean\")\n",
    "metrics_aug_clean  = eval(\"bert_augmented\", split=\"clean\")"
   ],
   "metadata": {},
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-2810358293.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[bert_original] Predicting on clean test…\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[bert_original] Saved to results/bert_original/clean/\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-2810358293.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[bert_augmented] Predicting on clean test…\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[bert_augmented] Saved to results/bert_augmented/clean/\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metrics_orig_pert  = eval(\"bert_original\",  split=\"perturbed\")\n",
    "metrics_aug_pert   = eval(\"bert_augmented\", split=\"perturbed\")"
   ],
   "metadata": {},
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-2810358293.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[bert_original] Predicting on perturbed test…\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[bert_original] Saved to results/bert_original/perturbed/\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-2810358293.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[bert_augmented] Predicting on perturbed test…\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[bert_augmented] Saved to results/bert_augmented/perturbed/\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "for m in MODELS:\n",
    "    for s in SPLITS:\n",
    "        p = OUT_ROOT / m / s / \"metrics.csv\"\n",
    "        if not p.exists():\n",
    "            print(f\"[missing] {p}\")\n",
    "            continue\n",
    "        d = pd.read_csv(p).iloc[0].to_dict()\n",
    "        d = {k.replace(\"test_\", \"\").replace(\"eval_\", \"\"): v for k, v in d.items()}\n",
    "        d.update({\"model\": m, \"split\": s})\n",
    "        rows.append(d)\n",
    "\n",
    "metrics_all = pd.DataFrame(rows)\n",
    "\n",
    "ordered = [\"model\",\"split\",\"accuracy\",\"f1_macro\",\"f1_weighted\",\n",
    "           \"hate_speech_precision\",\"hate_speech_recall\",\"hate_speech_f1\",\n",
    "           \"offensive_precision\",\"offensive_recall\",\"offensive_f1\",\n",
    "           \"neither_precision\",\"neither_recall\",\"neither_f1\",\n",
    "           \"loss\",\"runtime\",\"samples_per_second\",\"steps_per_second\"]\n",
    "metrics_all = metrics_all[[c for c in ordered if c in metrics_all.columns] +\n",
    "                          [c for c in metrics_all.columns if c not in ordered]]\n",
    "\n",
    "display(metrics_all.sort_values([\"model\",\"split\"]).reset_index(drop=True))\n",
    "\n",
    "if {\"model\",\"split\",\"f1_macro\"} <= set(metrics_all.columns):\n",
    "    pivot = metrics_all.pivot(index=\"model\", columns=\"split\", values=\"f1_macro\")\n",
    "    if \"clean\" in pivot and \"perturbed\" in pivot:\n",
    "        pivot[\"delta_f1_macro\"] = pivot[\"perturbed\"] - pivot[\"clean\"]\n",
    "        display(pivot)\n"
   ],
   "metadata": {},
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "            model      split  accuracy  f1_macro  f1_weighted  \\\n",
       "0  bert_augmented      clean  0.910974  0.782666     0.912823   \n",
       "1  bert_augmented  perturbed  0.900215  0.767382     0.904056   \n",
       "2   bert_original      clean  0.901829  0.771690     0.906804   \n",
       "3   bert_original  perturbed  0.898063  0.766707     0.902973   \n",
       "\n",
       "   hate_speech_precision  hate_speech_recall  hate_speech_f1  \\\n",
       "0               0.473684            0.546729        0.507592   \n",
       "1               0.423913            0.546729        0.477551   \n",
       "2               0.413559            0.570093        0.479371   \n",
       "3               0.412969            0.565421        0.477318   \n",
       "\n",
       "   offensive_precision  offensive_recall  offensive_f1  neither_precision  \\\n",
       "0             0.950350          0.944078      0.947203           0.903437   \n",
       "1             0.949982          0.930184      0.939979           0.886035   \n",
       "2             0.953331          0.929489      0.941259           0.900974   \n",
       "3             0.952126          0.925669      0.938711           0.883387   \n",
       "\n",
       "   neither_recall  neither_f1      loss  runtime  samples_per_second  \\\n",
       "0          0.8832    0.893204  0.284007   6.0313             616.449   \n",
       "1          0.8832    0.884615  0.346168   6.0985             609.658   \n",
       "2          0.8880    0.894440  0.315610   6.1768             601.926   \n",
       "3          0.8848    0.884093  0.326284   6.0829             611.218   \n",
       "\n",
       "   steps_per_second  model_preparation_time  \n",
       "0            19.399                  0.0042  \n",
       "1            19.185                  0.0029  \n",
       "2            18.942                  0.0049  \n",
       "3            19.234                  0.0028  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-72e4000e-3892-4a6c-8aa9-1fe32bc2661b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>hate_speech_precision</th>\n",
       "      <th>hate_speech_recall</th>\n",
       "      <th>hate_speech_f1</th>\n",
       "      <th>offensive_precision</th>\n",
       "      <th>offensive_recall</th>\n",
       "      <th>offensive_f1</th>\n",
       "      <th>neither_precision</th>\n",
       "      <th>neither_recall</th>\n",
       "      <th>neither_f1</th>\n",
       "      <th>loss</th>\n",
       "      <th>runtime</th>\n",
       "      <th>samples_per_second</th>\n",
       "      <th>steps_per_second</th>\n",
       "      <th>model_preparation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert_augmented</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.910974</td>\n",
       "      <td>0.782666</td>\n",
       "      <td>0.912823</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.546729</td>\n",
       "      <td>0.507592</td>\n",
       "      <td>0.950350</td>\n",
       "      <td>0.944078</td>\n",
       "      <td>0.947203</td>\n",
       "      <td>0.903437</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.284007</td>\n",
       "      <td>6.0313</td>\n",
       "      <td>616.449</td>\n",
       "      <td>19.399</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert_augmented</td>\n",
       "      <td>perturbed</td>\n",
       "      <td>0.900215</td>\n",
       "      <td>0.767382</td>\n",
       "      <td>0.904056</td>\n",
       "      <td>0.423913</td>\n",
       "      <td>0.546729</td>\n",
       "      <td>0.477551</td>\n",
       "      <td>0.949982</td>\n",
       "      <td>0.930184</td>\n",
       "      <td>0.939979</td>\n",
       "      <td>0.886035</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.346168</td>\n",
       "      <td>6.0985</td>\n",
       "      <td>609.658</td>\n",
       "      <td>19.185</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_original</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.901829</td>\n",
       "      <td>0.771690</td>\n",
       "      <td>0.906804</td>\n",
       "      <td>0.413559</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.479371</td>\n",
       "      <td>0.953331</td>\n",
       "      <td>0.929489</td>\n",
       "      <td>0.941259</td>\n",
       "      <td>0.900974</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.894440</td>\n",
       "      <td>0.315610</td>\n",
       "      <td>6.1768</td>\n",
       "      <td>601.926</td>\n",
       "      <td>18.942</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert_original</td>\n",
       "      <td>perturbed</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.766707</td>\n",
       "      <td>0.902973</td>\n",
       "      <td>0.412969</td>\n",
       "      <td>0.565421</td>\n",
       "      <td>0.477318</td>\n",
       "      <td>0.952126</td>\n",
       "      <td>0.925669</td>\n",
       "      <td>0.938711</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>0.8848</td>\n",
       "      <td>0.884093</td>\n",
       "      <td>0.326284</td>\n",
       "      <td>6.0829</td>\n",
       "      <td>611.218</td>\n",
       "      <td>19.234</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72e4000e-3892-4a6c-8aa9-1fe32bc2661b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-72e4000e-3892-4a6c-8aa9-1fe32bc2661b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-72e4000e-3892-4a6c-8aa9-1fe32bc2661b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-1de7a2f5-e2e2-40f4-b3ab-9006865efd5f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1de7a2f5-e2e2-40f4-b3ab-9006865efd5f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-1de7a2f5-e2e2-40f4-b3ab-9006865efd5f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"        display(pivot)\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"bert_original\",\n          \"bert_augmented\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"perturbed\",\n          \"clean\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005682249194007777,\n        \"min\": 0.8980634749865519,\n        \"max\": 0.9109736417428724,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9002151694459387,\n          0.8980634749865519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007374810650210182,\n        \"min\": 0.7667070312422531,\n        \"max\": 0.7826664733050324,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7673817816674959,\n          0.7667070312422531\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_weighted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004411340911475024,\n        \"min\": 0.9029726580933988,\n        \"max\": 0.91282291226932,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9040559176845968,\n          0.9029726580933988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hate_speech_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028875865437744765,\n        \"min\": 0.4129692832764505,\n        \"max\": 0.4736842105263157,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.4239130434782608,\n          0.4129692832764505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hate_speech_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012289512334937289,\n        \"min\": 0.5467289719626168,\n        \"max\": 0.5700934579439252,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5467289719626168,\n          0.5700934579439252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hate_speech_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014784646406969039,\n        \"min\": 0.4773175542406311,\n        \"max\": 0.5075921908893709,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.4775510204081633,\n          0.4773175542406311\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"offensive_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0015662740293551727,\n        \"min\": 0.9499822632139056,\n        \"max\": 0.9533309583184896,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9499822632139056,\n          0.9521257591997142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"offensive_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008063417420190802,\n        \"min\": 0.9256686349426884,\n        \"max\": 0.944077804793331,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9301840916985064,\n          0.9256686349426884\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"offensive_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00375709707980583,\n        \"min\": 0.938710813666784,\n        \"max\": 0.9472033455305804,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.93997893997894,\n          0.938710813666784\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neither_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010207850117663652,\n        \"min\": 0.8833865814696485,\n        \"max\": 0.9034369885433716,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8860353130016051,\n          0.8833865814696485\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neither_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0022627416997969647,\n        \"min\": 0.8832,\n        \"max\": 0.888,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8832,\n          0.888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neither_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005493666306236055,\n        \"min\": 0.8840927258193445,\n        \"max\": 0.8944399677679291,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8846153846153846,\n          0.8840927258193445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025970145560202832,\n        \"min\": 0.2840065360069275,\n        \"max\": 0.3461682796478271,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3461682796478271,\n          0.3262840807437897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.060235724449864504,\n        \"min\": 6.0313,\n        \"max\": 6.1768,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6.0985,\n          6.0829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.006643953434635,\n        \"min\": 601.926,\n        \"max\": 616.449,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          609.658,\n          611.218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18898500822375697,\n        \"min\": 18.942,\n        \"max\": 19.399,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          19.185,\n          19.234\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_preparation_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001023067283548187,\n        \"min\": 0.0028,\n        \"max\": 0.0049,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0029,\n          0.0028\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "split              clean  perturbed  delta_f1_macro\n",
       "model                                              \n",
       "bert_augmented  0.782666   0.767382       -0.015285\n",
       "bert_original   0.771690   0.766707       -0.004983"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-9a5debf6-b9b9-44c0-915b-0c74d0878b07\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>clean</th>\n",
       "      <th>perturbed</th>\n",
       "      <th>delta_f1_macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert_augmented</th>\n",
       "      <td>0.782666</td>\n",
       "      <td>0.767382</td>\n",
       "      <td>-0.015285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_original</th>\n",
       "      <td>0.771690</td>\n",
       "      <td>0.766707</td>\n",
       "      <td>-0.004983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a5debf6-b9b9-44c0-915b-0c74d0878b07')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-9a5debf6-b9b9-44c0-915b-0c74d0878b07 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-9a5debf6-b9b9-44c0-915b-0c74d0878b07');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-0c2674b9-cf87-4564-8b62-135b510a8915\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c2674b9-cf87-4564-8b62-135b510a8915')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-0c2674b9-cf87-4564-8b62-135b510a8915 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_c5720ad9-1e9d-4494-84b1-c189b26455f3\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pivot')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_c5720ad9-1e9d-4494-84b1-c189b26455f3 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('pivot');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "pivot",
       "summary": "{\n  \"name\": \"pivot\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"bert_original\",\n          \"bert_augmented\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0077614167837251865,\n        \"min\": 0.771690172426258,\n        \"max\": 0.7826664733050324,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.771690172426258,\n          0.7826664733050324\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perturbed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0004771206012976814,\n        \"min\": 0.7667070312422531,\n        \"max\": 0.7673817816674959,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7667070312422531,\n          0.7673817816674959\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007284296182427505,\n        \"min\": -0.01528469163753643,\n        \"max\": -0.004983141184004891,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.004983141184004891,\n          -0.01528469163753643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    }
   ]
  }
 ]
}